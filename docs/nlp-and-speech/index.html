<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>NLP and Speech - FederatedScope</title>
<meta name="description" content="About NLP and Speech">


  <meta name="author" content="Data Analytics and Intelligence Lab (DAIL) of DAMO Academy">
  
  <meta property="article:author" content="Data Analytics and Intelligence Lab (DAIL) of DAMO Academy">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="FederatedScope">
<meta property="og:title" content="NLP and Speech">
<meta property="og:url" content="https://federatedscopeteam.github.io/docs/nlp-and-speech/">


  <meta property="og:description" content="About NLP and Speech">



  <meta property="og:image" content="https://federatedscopeteam.github.io/assets/images/site-logo.png">



  <meta name="twitter:site" content="@mmistakes">
  <meta name="twitter:title" content="NLP and Speech">
  <meta name="twitter:description" content="About NLP and Speech">
  <meta name="twitter:url" content="https://federatedscopeteam.github.io/docs/nlp-and-speech/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://federatedscopeteam.github.io/assets/images/site-logo.png">
    
  

  



  <meta property="article:published_time" content="2023-09-06T05:40:29-04:00">



  <meta property="article:modified_time" content="2022-04-13T20:46:43-04:00">



  

  


<link rel="canonical" href="https://federatedscopeteam.github.io/docs/nlp-and-speech/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Data Analytics and Intelligence Lab (DAIL) of DAMO Academy",
      "url": "https://federatedscopeteam.github.io/",
      "sameAs": ["https://twitter.com/mmistakes","https://www.facebook.com/michaelrose"]
    
  }
</script>


  <meta name="google-site-verification" content="UQj93ERU9zgECodaaXgVpkjrFn9UrDMEzVamacSoQ8Y" />






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="FederatedScope Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="shortcut icon" type="image/png" href="https://img.alicdn.com/imgextra/i1/O1CN018QJmTK1vLxKVTFziU_!!6000000006157-2-tps-436-436.png">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--tuto">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          <img src=https://img.alicdn.com/imgextra/i2/O1CN01cCDBCY1a354ojQtsJ_!!6000000003273-2-tps-2536-383.png alt="Logo" height="30" width="210">
          <span class="site-subtitle"></span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/docs/documentation/" target="">Tutorials</a>
            </li><li class="masthead__menu-item">
              <a href="https://colab.research.google.com/github/alibaba/FederatedScope" target="_blank">Playground</a>
            </li><li class="masthead__menu-item">
              <a href="/refs/index" target="_blank">API References</a>
            </li><li class="masthead__menu-item">
              <a href="/news/" target="">News</a>
            </li><li class="masthead__menu-item">
              <a href="/pub/" target="">Publications</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Beginner</span>
        

        
        <ul>
          
            <li><a href="/docs/installation/">Installation</a></li>
          
            <li><a href="/docs/examples/">Start With Examples</a></li>
          
            <li><a href="/docs/own-case/">Start Your Own Case</a></li>
          
            <li><a href="/docs/datazoo/">DataZoo</a></li>
          
            <li><a href="/docs/modelzoo/">ModelZoo</a></li>
          
            <li><a href="/docs/algozoo/">AlgoZoo</a></li>
          
            <li><a href="/docs/use-hpo/">Tuning Federated Learning</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Advanced</span>
        

        
        <ul>
          
            <li><a href="/docs/fs-data/">FS data module</a></li>
          
            <li><a href="/docs/event-driven-architecture/">Event-driven Architecture</a></li>
          
            <li><a href="/docs/workers/">Workers</a></li>
          
            <li><a href="/docs/new-type/">New Types of Messages and Handlers</a></li>
          
            <li><a href="/docs/protected-msg/">Privacy Protection for Message</a></li>
          
            <li><a href="/docs/trainer/">Local Learning Abstraction: Trainer</a></li>
          
            <li><a href="/docs/pfl/">Personalized FL</a></li>
          
            <li><a href="/docs/cross-device/">Cross-Device FL</a></li>
          
            <li><a href="/docs/cross-silo/">Cross-Silo FL</a></li>
          
            <li><a href="/docs/improve-hpo/">Accelerating Federated HPO</a></li>
          
            <li><a href="/docs/simulation-and-deployment/">Simulation and Deployment</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Applications</span>
        

        
        <ul>
          
            <li><a href="/docs/recommendation/">Recommendation</a></li>
          
            <li><a href="/docs/dp/">Differential Privacy</a></li>
          
            <li><a href="/docs/privacy-attacks/">Privacy Attacks</a></li>
          
            <li><a href="/docs/graph/">Graph</a></li>
          
            <li><a href="/docs/nlp-and-speech/" class="active">NLP and Speech</a></li>
          
            <li><a href="/docs/llm/">LLM</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Get Involved</span>
        

        
        <ul>
          
            <li><a href="/docs/community/">Join Our Community</a></li>
          
            <li><a href="/docs/contributor/">Contributing to FederatedScope</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="NLP and Speech">
    <meta itemprop="description" content="About NLP and Speech">
    <meta itemprop="datePublished" content="2023-09-06T05:40:29-04:00">
    <meta itemprop="dateModified" content="2022-04-13T20:46:43-04:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">NLP and Speech
</h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#background">Background</a></li><li><a href="#natural-language-processing-nlp">Natural Language Processing (NLP)</a><ul><li><a href="#datasets">Datasets</a></li><li><a href="#models">Models</a></li><li><a href="#start-an-example">Start an example</a></li><li><a href="#customize-your-nlp-task">Customize your NLP task</a></li></ul></li><li><a href="#speech-coming-soon">Speech (Coming soon)</a></li><li><a href="#reference">Reference</a></li></ul>

            </nav>
          </aside>
        
        <div class="eqtextwidth-content">
        <p><a name="bJdWk"></a></p>
<h2 id="background">Background</h2>

<p>Recently, privacy-preserving methods gain increasing attentions in machine learning (ML) applications using linguistic data ¬†including text and audio, due to the fact that linguistic data can involve a wealth of information relating to an identified or identifiable natural person, such as the physiological, psychological, economic, cultural or social identity.</p>

<p>Federated Learning (FL) methods show promising results for collaboratively training models from a large number of clients without sharing their private linguistic data. To facilitate FL research in linguistic data, FederatedScope provides several built-in linguistic datasets and supports various tasks such as language modeling and text classification with various FL algorithms.</p>

<p><a name="Yzwrs"></a></p>
<h2 id="natural-language-processing-nlp">Natural Language Processing (NLP)</h2>

<p><a name="ZhStB"></a></p>
<h3 id="datasets">Datasets</h3>

<p>We provide three popular text datasets for next-character prediction, next-word prediction, and sentiment analysis.</p>

<ul>
  <li>Shakespeare: a federation text dataset of Shakespeare Dialogues from <a href="https://leaf.cmu.edu/">LEAF</a> [1] for next-character prediction, which contains 422,615 sentences and about 1,100 clients.</li>
  <li>subReddit: a federation text dataset and subsampled of reddit from LEAF for next-word prediction, which contains 216,858 sentences and about 800 clients.</li>
  <li>Sentiment140: a federation text dataset of Twitter from LEAF for Sentiment Analysis, which contains 1,600,498 sentences, about 660,000 ¬†clients.</li>
</ul>

<p><a name="eHVuQ"></a></p>
<h3 id="models">Models</h3>

<p>We provide a LSTM model implementation in <code class="language-plaintext highlighter-rouge">federatedscope/nlp/model</code></p>

<ul>
  <li><strong>LSTM:</strong> a type of RNN that solves the vanishing gradient problem through additional cells, input and output gates. (<code class="language-plaintext highlighter-rouge">cfg.model.type = 'lstm'</code>)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">hidden</span><span class="p">,</span>
                 <span class="n">out_channels</span><span class="p">,</span>
                 <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="k">pass</span>
</code></pre></div></div>

<ul>
  <li>Currently, we are working on implement more interfaces to support more popular NLP Transformer models and more NLP tasks with <a href="https://github.com/huggingface/transformers">HuggingFace Transformers</a> [2].</li>
</ul>

<p><a name="nOGSF"></a></p>
<h3 id="start-an-example">Start an example</h3>

<p>Next-character/word prediction is a classic NLP task as it can be applied in many consumer applications and appropriately be modeled by statistical language models, we show how to achieve next-character prediction in cross-device FL setting.</p>

<ul>
  <li>Here we implement a simple LSTM model for next-character prediction: taking an English characters sequence as input, the model learns to predict the next possible character. After registering the model, we can use it by specifying <code class="language-plaintext highlighter-rouge">cfg.model.type=lstm</code> and ¬†hyper-parameters such as ¬†<code class="language-plaintext highlighter-rouge">cfg.model.in_channels=80, cfg.model.out_channels=80, cfg.model.emd_size=8</code>. ¬†Complete codes are in <code class="language-plaintext highlighter-rouge">federatedscope/nlp/model/rnn.py</code> and <code class="language-plaintext highlighter-rouge">federatedscope/nlp/model/model_builder.py</code>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">hidden</span><span class="p">,</span>
                 <span class="n">out_channels</span><span class="p">,</span>
                 <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span>\
            <span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span>
                <span class="n">input_size</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span>
                <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span>
                <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">):</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># change dimension to (B, C, T)
</span>        <span class="n">final_word</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">final_word</span>
</code></pre></div></div>

<ul>
  <li>For the dataset, we use the Shakespeare dataset from <a href="https://leaf.cmu.edu/">LEAF</a>, which is built from <em>The Complete Works of William Shakespeare</em>, ¬†and partitioned to ~1100 clients (speaking roles) from 422615. ¬†We can specify the <code class="language-plaintext highlighter-rouge">cfg.dataset.type=shakespeare</code> and adjust the fraction of data subsample (<code class="language-plaintext highlighter-rouge">cfg.data.sub_sample=0.2</code>), and train/val/test ratio (``cfg.data.splits=[0.6,0.2,0.2]). Complete NLP data codes are in<code class="language-plaintext highlighter-rouge">federatedscope/nlp/dataset</code>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LEAF_NLP</span><span class="p">(</span><span class="n">LEAF</span><span class="p">):</span>
    <span class="s">"""
    LEAF NLP dataset from
    
    leaf.cmu.edu
    
    self:
        root (str): root path.
        name (str): name of dataset, ‚Äòshakespeare‚Äô or ‚Äòxxx‚Äô.
        s_frac (float): fraction of the dataset to be used; default=0.3.
        tr_frac (float): train set proportion for each task; default=0.8.
        val_frac (float): valid set proportion for each task; default=0.0.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">root</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">s_frac</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
            <span class="n">tr_frac</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">val_frac</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
            <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
            <span class="n">target_transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">pass</span>
</code></pre></div></div>

<ul>
  <li>To enable large-scale clients simulation, we provide online aggregator in standalone mode to save the memory, which ¬†maintains only three model objects for the FL server aggregation. We can use this feature by specifying <code class="language-plaintext highlighter-rouge">cfg.federate.online_aggr = True</code> and <code class="language-plaintext highlighter-rouge">federate.share_local_model=True</code> , more details about this feature can be found in <a href="/docs/simulation-and-deployment">the post ‚ÄúSimulation and Deployment‚Äù</a>.</li>
  <li>To handle the non-i.i.d. challenge, FederatedScope supports several SOTA <a href="/docs/pfl">personalization</a> algorithms and easy extension.</li>
  <li>To enable partial clients participation in each FL round, we provide clients sampling feature with various configuration manners: 1) <code class="language-plaintext highlighter-rouge">cfg.federate.sample_client_rate</code>, which is in the range (0, 1] and indicates selecting partial clients using random sampling with replacement; 2) <code class="language-plaintext highlighter-rouge">cfg.federate.sample_client_num</code> , which is an integer to indicate sample client number at each round.</li>
</ul>

<p>With these specification, we can run the experiment with</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">main</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">cfg</span> <span class="n">federatedscope</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">baseline</span><span class="o">/</span><span class="n">fedavg_lstm_on_shakespeare</span><span class="p">.</span><span class="n">yaml</span>
</code></pre></div></div>

<p>You will get the accuracy of FedAvg algorithm around <code class="language-plaintext highlighter-rouge">43.80%</code>.</p>

<p>Other NLP related scripts to run the next-character prediction experiments can be found in <code class="language-plaintext highlighter-rouge">federatedscope/nlp/baseline</code>.</p>

<p><a name="MK5wA"></a></p>
<h3 id="customize-your-nlp-task">Customize your NLP task</h3>

<p>FederatedScope enables users to easily implement and register more NLP datasets and models.</p>

<ul>
  <li>Implement and register your own NLP data
```python
    <h1 id="federatedscopecontribdatamy_nlp_datapy">federatedscope/contrib/data/my_nlp_data.py</h1>
  </li>
</ul>

<p>import torch
import copy
import numpy as np</p>

<p>from federatedscope.register import register_data</p>

<p>def get_my_nlp_data(config):
    r‚Äù‚Äù‚Äù
        This function returns a dictionary, where key is the client id and 
    value is the data dict of each client with ‚Äòtrain‚Äô, ‚Äòtest‚Äô or ‚Äòval‚Äô.
    		NOTE: client_id 0 is SERVER!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Returns:
      dict: {
                'client_id': {
                    'train': DataLoader or Data,
                    'test': DataLoader or Data,
                    'val': DataLoader or Data,
                }
            }
"""
import numpy as np
from torch.utils.data import DataLoader

# Build data
dataset = LEAF_NLP(root=path,
                   name="twitter",
                   s_frac=config.data.subsample,
                   tr_frac=splits[0],
                   val_frac=splits[1],
                   seed=1234,
                   transform=transform)

client_num = min(len(dataset), config.federate.client_num
                 ) if config.federate.client_num &gt; 0 else len(dataset)
config.merge_from_list(['federate.client_num', client_num])

# get local dataset
data_local_dict = dict()
for client_idx in range(client_num):
    dataloader = {
        'train': DataLoader(dataset[client_idx]['train'],
                            batch_size,
                            shuffle=config.data.shuffle,
                            num_workers=config.data.num_workers),
        'test': DataLoader(dataset[client_idx]['test'],
                           batch_size,
                           shuffle=False,
                           num_workers=config.data.num_workers)
    }
    if 'val' in dataset[client_idx]:
        dataloader['val'] = DataLoader(dataset[client_idx]['val'],
                                       batch_size,
                                       shuffle=False,
                                       num_workers=config.data.num_workers)

    data_local_dict[client_idx + 1] = dataloader

return data_local_dict, confi
</code></pre></div></div>

<p>def call_my_data(config):
    if config.data.type == ‚Äúmy_nlp_data‚Äù:
        data, modified_config = get_my_nlp_data(config)
        return data, modified_config</p>

<p>register_data(‚Äúmy_nlp_data‚Äù, call_my_data)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 

-  Implement and register your own NLP model 
```python
import torch
from federatedscope.register import register_model


class  KIM_CNN(nn.Module):
  """
  		ref to Kim's CNN text classification paper [3]
  		https://github.com/Shawn1993/cnn-text-classification-pytorch
  """
    def __init__(self, args):
        super(CNN_Text, self).__init__()
        self.args = args
        
        V = args.embed_num
        D = args.embed_dim
        C = args.class_num
        Ci = 1
        Co = args.kernel_num
        Ks = args.kernel_sizes

        self.embed = nn.Embedding(V, D)
        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])
        self.dropout = nn.Dropout(args.dropout)
        self.fc1 = nn.Linear(len(Ks) * Co, C)

        if self.args.static:
            self.embed.weight.requires_grad = False

    def forward(self, x):
        x = self.embed(x)  # (N, W, D)
    
        x = x.unsqueeze(1)  # (N, Ci, W, D)

        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, Co, W), ...]*len(Ks)

        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)

        x = torch.cat(x, 1)

        x = self.dropout(x)  # (N, len(Ks)*Co)
        logit = self.fc1(x)  # (N, C)
        return logit

     
def call_my_net(model_config, local_data):
    if model_config.type == "my_nlp_model":
        model = KIM_CNN(args=model_config)
        return model

register_model("my_nlp_model", call_my_net)
</code></pre></div></div>

<ul>
  <li>Then with fruitful ¬†built-in FL experiments scripts , users can run own FL experiments by <em>replacing</em> the model type and dataset type in the provided ¬†scripts.</li>
</ul>

<p><a name="Txa84"></a></p>
<h2 id="speech-coming-soon">Speech (Coming soon)</h2>

<p>We are working on implement more interfaces to support more Conformer [4] models and more speech-related tasks with <a href="https://github.com/wenet-e2e/wenet">WeNet</a> [5], which is designed for various end-2-end speech recognition tasks and provides full stack solutions for production and real-world applications.</p>

<p><a name="Reference"></a></p>
<h2 id="reference">Reference</h2>

<p>[1] Caldas, Sebastian, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Koneƒçn√Ω, H. Brendan McMahan, Virginia Smith, and Ameet Talwalkar. ‚ÄúLeaf: A benchmark for federated settings.‚Äù <em>arXiv preprint arXiv:1812.01097</em> (2018).</p>

<p>[2] Wolf, Thomas, et al. ‚ÄúHuggingface‚Äôs transformers: State-of-the-art natural language processing.‚Äù <em>arXiv preprint arXiv:1910.03771</em> (2019).</p>

<p>[3] Yoon Kim. 2014. <a href="https://aclanthology.org/D14-1181">Convolutional Neural Networks for Sentence Classification</a>. In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1746‚Äì1751, Doha, Qatar.</p>

<p>[4] Gulati, Anmol, et al. ‚ÄúConformer: Convolution-augmented transformer for speech recognition.‚Äù <em>arXiv preprint arXiv:2005.08100</em> (2020).</p>

<p>[5] Zhang, Binbin, et al. ‚ÄúWenet: Production first and production ready end-to-end speech recognition toolkit.‚Äù <em>arXiv e-prints</em> (2021): arXiv-2102.</p>

        </div>
        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2022-04-13">April 13, 2022</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/docs/graph/" class="pagination--pager" title="Graph
">Previous</a>
    
    
      <a href="/docs/community/" class="pagination--pager" title="Join Our Community
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

      <div align="center" style="margin: 1em 0;">
        <ins class="adsbygoogle"
             style="display:block; border-bottom: initial;"
             data-ad-client="ca-pub-7328585512091257"
             data-ad-slot="3049671934"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
      </div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><div class="search-searchbar"></div>
  <div class="search-hits"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <div class="footer-left-box">
          <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
          <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/alibaba/FederatedScope" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://damo.alibaba.com/labs/data-analytics-and-intelligence" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i> Team page</a></li>
        
      
        
          <li><a href="https://join.slack.com/t/federatedscopeteam/shared_invite/zt-1apmfjqmc-hvpYbsWJdm7D93wPNXbqww" rel="nofollow noopener noreferrer"><i class="fab fa-slack" aria-hidden="true"></i> Slack</a></li>
        
      
        
          <li><a href="javascript:;" rel="nofollow noopener noreferrer"><i class="dingding" aria-hidden="true"></i> Join DingGroup üëâ</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Data Analytics and Intelligence Lab (DAIL) of DAMO Academy. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

        </div>
        <div class="footer-group-img-box">
          <img class="footer-group-img" src="https://img.alicdn.com/imgextra/i2/O1CN01NSWjlJ1q8bliVtjRp_!!6000000005451-0-tps-924-926.jpg" alt="">
        </div>
      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>


<!-- Including InstantSearch.js library and styling -->
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch-theme-algolia.min.css">

<script>
// Instanciating InstantSearch.js with Algolia credentials
const search = instantsearch({
  appId: 'QB6HVGBSBA',
  apiKey: '9d5014e5bbc77372547bce778dfa5663',
  indexName: 'minimal_mistakes',
  searchParameters: {
    restrictSearchableAttributes: [
      'title',
      'content'
    ]
  }
});

const hitTemplate = function(hit) {
  const url = hit.url;
  const title = hit._highlightResult.title.value;
  const content = hit._highlightResult.html.value;

  return `
    <div class="list__item">
      <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
        <h2 class="archive__item-title" itemprop="headline"><a href="${url}">${title}</a></h2>
        <div class="archive__item-excerpt" itemprop="description">${content}</div>
      </article>
    </div>
  `;
}

// Adding searchbar and results widgets
search.addWidget(
  instantsearch.widgets.searchBox({
    container: '.search-searchbar',
    poweredBy: true,
    placeholder: 'Enter your search term...'
  })
);
search.addWidget(
  instantsearch.widgets.hits({
    container: '.search-hits',
    templates: {
      item: hitTemplate,
      empty: 'No results',
    }
  })
);

// Starting the search only when toggle is clicked
$(document).ready(function () {
  $(".search__toggle").on("click", function() {
    if(!search.started) {
      search.start();
    }
  });
});
</script>





  <script>
  window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
  ga('create','UA-2011187-3','auto');
  ga('set', 'anonymizeIp', true);
  ga('send','pageview')
</script>
<script src="https://www.google-analytics.com/analytics.js" async></script>








<!-- Mathjax Support -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

    <style>
      .google-auto-placed {
        margin: 2em auto;
      }
    </style>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>

  </body>
</html>
