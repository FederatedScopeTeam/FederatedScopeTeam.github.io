<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Attack Module References &mdash; federatedscope 0.2.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Federated Matrix Factorization Module References" href="mf.html" />
    <link rel="prev" title="Auto-tuning Module References" href="autotune.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> federatedscope
          </a>
              <div class="version">
                0.2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="core.html">Core Module References</a></li>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Federated Computer Vision  Module References</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Federated Natural Language Processing  Module References</a></li>
<li class="toctree-l1"><a class="reference internal" href="gfl.html">Federated Graph Learning  Module References</a></li>
<li class="toctree-l1"><a class="reference internal" href="autotune.html">Auto-tuning Module References</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Attack Module References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-federatedscope.attack.privacy_attacks">federatedscope.attack.privacy_attacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-federatedscope.attack.worker_as_attacker">federatedscope.attack.worker_as_attacker</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-federatedscope.attack.auxiliary">federatedscope.attack.auxiliary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-federatedscope.attack.trainer">federatedscope.attack.trainer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mf.html">Federated Matrix Factorization Module References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">federatedscope</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Attack Module References</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/attack.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="attack-module-references">
<h1>Attack Module References<a class="headerlink" href="#attack-module-references" title="Permalink to this headline">¶</a></h1>
<section id="module-federatedscope.attack.privacy_attacks">
<span id="federatedscope-attack-privacy-attacks"></span><h2>federatedscope.attack.privacy_attacks<a class="headerlink" href="#module-federatedscope.attack.privacy_attacks" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.DLG">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.privacy_attacks.</span></span><span class="sig-name descname"><span class="pre">DLG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_ite</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_loss_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_diff_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_one_hot_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/reconstruction_opt.html#DLG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.DLG" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the paper “Deep Leakage from Gradients”:
<a class="reference external" href="https://papers.nips.cc/paper/2019/file/">https://papers.nips.cc/paper/2019/file/</a>     60a6c4002cc7b29142def8871531281a-Paper.pdf</p>
<p class="rubric">References</p>
<p>Zhu, Ligeng, Zhijian Liu, and Song Han. “Deep leakage from gradients.”
Advances in Neural Information Processing Systems 32 (2019).</p>
<dl>
<dt>Args:</dt><dd><ul class="simple">
<li><p>max_ite (int): the max iteration number;</p></li>
<li><p>lr (float): learning rate in optimization based reconstruction;</p></li>
<li><p>federate_loss_fn (object): The loss function used in FL training;</p></li>
<li><p>device (str): the device running the reconstruction;</p></li>
<li><p>federate_method (str): The federated learning method;</p></li>
<li><p>federate_lr (float):The learning rate used in FL training;</p></li>
</ul>
<p>default None.
- optim (str): The optimization method used in reconstruction;
default: “Adam”; supported: ‘sgd’, ‘adam’, ‘lbfgs’
- info_diff_type (str): The type of loss between the
ground-truth gradient/parameter updates info and the
reconstructed info; default: “l2”
- is_one_hot_label (bool): whether the label is one-hot;
default: False</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.DLG.get_original_gradient_from_para">
<span class="sig-name descname"><span class="pre">get_original_gradient_from_para</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_info</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_para_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/reconstruction_opt.html#DLG.get_original_gradient_from_para"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.DLG.get_original_gradient_from_para" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer the model parameter updates to gradient based on:</p>
<div class="math notranslate nohighlight">
\[P_{t} = P - \eta g,\]</div>
<p>where
<span class="math notranslate nohighlight">\(P_{t}\)</span> is the parameters updated by the client at current round;
<span class="math notranslate nohighlight">\(P\)</span> is the parameters of the global model at the end of the
last round;
<span class="math notranslate nohighlight">\(\eta\)</span> is the learning rate of clients’ local training;
<span class="math notranslate nohighlight">\(g\)</span> is the gradient</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>-</em>) – The model owned by the Server</p></li>
<li><p><strong>original_info</strong> (<em>-</em>) – The model parameter updates received by</p></li>
<li><p><strong>Server</strong> – </p></li>
<li><p><strong>model_para_name</strong> (<em>-</em>) – The list of model name. Be sure the</p></li>
</ul>
</dd>
</dl>
<p>:param <code class="xref py py-attr docutils literal notranslate"><span class="pre">model_para_name</span></code> is consistent with the the key name in:
:param <code class="xref py py-attr docutils literal notranslate"><span class="pre">original_info</span></code>:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>original_gradient (list): the list of the gradient</p></li>
</ul>
<p>corresponding to the model updates</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.DLG.reconstruct">
<span class="sig-name descname"><span class="pre">reconstruct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_info</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_feature_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/reconstruction_opt.html#DLG.reconstruct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.DLG.reconstruct" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstruct the original training data and label.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The model used in FL; Type: object</p></li>
<li><p><strong>original_info</strong> – The message received to perform reconstruction,</p></li>
<li><p><strong>Type</strong> (<em>generate the original_info;</em>) – list</p></li>
<li><p><strong>data_feature_dim</strong> – The feature dimension of dataset; Type: list</p></li>
<li><p><strong>Tensor.Size</strong> (<em>or</em>) – </p></li>
<li><p><strong>num_class</strong> – the number of total classes in the dataset; Type: int</p></li>
<li><p><strong>batch_size</strong> – the number of samples in the batch that</p></li>
<li><p><strong>Type</strong> – int</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The reconstructed data (Tensor); Size: [batch_size,</p></li>
</ul>
<p>data_feature_dim]
- The reconstructed label (Tensor): Size: [batch_size]</p>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.GANCRA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.privacy_attacks.</span></span><span class="sig-name descname"><span class="pre">GANCRA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_label_ind</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator_train_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sav_pth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'data/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/GAN_based_attack.html#GANCRA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.GANCRA" title="Permalink to this definition">¶</a></dt>
<dd><p>The implementation of GAN based class representative attack.
<a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3133956.3134012">https://dl.acm.org/doi/abs/10.1145/3133956.3134012</a></p>
<p class="rubric">References</p>
<p>Hitaj, Briland, Giuseppe Ateniese, and Fernando Perez-Cruz.</p>
<p>“Deep models under the GAN: information leakage from collaborative deep
learning.” Proceedings of the 2017 ACM SIGSAC conference on computer
and communications security. 2017.</p>
<blockquote>
<div><dl>
<dt>Args:</dt><dd><ul class="simple">
<li><p>target_label_ind (int): the label index whose representative</p></li>
<li><p>fl_model (object):</p></li>
<li><p>device (str or int): the device to run; ‘cpu’ or the device</p></li>
</ul>
<p>index to select; default: ‘cpu’.
- dataset_name (str): the dataset name; default: None
- noise_dim (int): the dimension of the noise that fed into the
generator; default: 100
- batch_size (int): the number of data generated into training;
default: 16
- generator_train_epoch (int): the number of training steps
when training the generator; default: 10
- lr (float): the learning rate of the generator training;
default: 0.001
- sav_pth (str): the path to save the generated data; default:
‘data/’
- round_num (int): the FL round that starting the attack;
default: -1.</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.GANCRA.generate_and_save_images">
<span class="sig-name descname"><span class="pre">generate_and_save_images</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/GAN_based_attack.html#GANCRA.generate_and_save_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.GANCRA.generate_and_save_images" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the generated data and the generator training loss</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.GANCRA.generator_loss">
<span class="sig-name descname"><span class="pre">generator_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">discriminator_output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/GAN_based_attack.html#GANCRA.generator_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.GANCRA.generator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the generator loss based on the discriminator’s output</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>discriminator_output</strong> (<em>Tensor</em>) – the discriminator’s output;
size: batch_size * n_class</p>
</dd>
</dl>
<p>Returns: generator_loss</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.GANCRA.update_discriminator">
<span class="sig-name descname"><span class="pre">update_discriminator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/GAN_based_attack.html#GANCRA.update_discriminator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.GANCRA.update_discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy the model of the server as the discriminator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>object</em>) – the model in the server</p>
</dd>
</dl>
<p>Returns: the discriminator</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.InvertGradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.privacy_attacks.</span></span><span class="sig-name descname"><span class="pre">InvertGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_ite</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_loss_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">federate_lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_TV</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_diff_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sim'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_one_hot_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/reconstruction_opt.html#InvertGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.InvertGradient" title="Permalink to this definition">¶</a></dt>
<dd><p>The implementation of “Inverting Gradients - How easy is it to break
privacy in federated learning?”.
Link: <a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/">https://proceedings.neurips.cc/paper/2020/hash/</a>     c4ede56bbd98819ae6112b20ac6bf145-Abstract.html</p>
<p class="rubric">References</p>
<p>Geiping, Jonas, et al. “Inverting gradients-how easy is it to break
privacy in federated learning?.” Advances in Neural Information
Processing Systems 33 (2020): 16937-16947.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_ite</strong> (<em>-</em>) – the max iteration number;</p></li>
<li><p><strong>lr</strong> (<em>-</em>) – learning rate in optimization based reconstruction;</p></li>
<li><p><strong>federate_loss_fn</strong> (<em>-</em>) – The loss function used in FL training;</p></li>
<li><p><strong>device</strong> (<em>-</em>) – the device running the reconstruction;</p></li>
<li><p><strong>federate_method</strong> (<em>-</em>) – The federated learning method;</p></li>
<li><p><strong>federate_lr</strong> (<em>-</em>) – The learning rate used in FL training;</p></li>
<li><p><strong>default</strong> (<em>reconstructed info;</em>) – None.</p></li>
<li><p><strong>alpha_TV</strong> (<em>-</em>) – the hyper-parameter of the total variance</p></li>
<li><p><strong>default</strong> – 0.001</p></li>
<li><p><strong>info_diff_type</strong> (<em>-</em>) – The type of loss between the</p></li>
<li><p><strong>the</strong> (<em>ground-truth gradient/parameter updates info and</em>) – </p></li>
<li><p><strong>default</strong> – “l2”</p></li>
<li><p><strong>optim</strong> (<em>-</em>) – The optimization method used in reconstruction;</p></li>
<li><p><strong>default</strong> – “Adam”; supported: ‘sgd’, ‘adam’, ‘lbfgs’</p></li>
<li><p><strong>info_diff_type</strong> – The type of loss between the</p></li>
<li><p><strong>the</strong> – </p></li>
<li><p><strong>default</strong> – “l2”</p></li>
<li><p><strong>is_one_hot_label</strong> (<em>-</em>) – whether the label is one-hot;</p></li>
<li><p><strong>default</strong> – False</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.PassivePropertyInference">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.privacy_attacks.</span></span><span class="sig-name descname"><span class="pre">PassivePropertyInference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classier</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_model_criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_clip</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_local_update_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_type_optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fl_lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/passive_PIA.html#PassivePropertyInference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.PassivePropertyInference" title="Permalink to this definition">¶</a></dt>
<dd><p>This is an implementation of the passive property inference
（algorithm 3 in Exploiting Unintended Feature Leakage
in Collaborative Learning: <a class="reference external" href="https://arxiv.org/pdf/1805.04049.pdf">https://arxiv.org/pdf/1805.04049.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.privacy_attacks.PassivePropertyInference.add_parameter_updates">
<span class="sig-name descname"><span class="pre">add_parameter_updates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter_updates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prop</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/privacy_attacks/passive_PIA.html#PassivePropertyInference.add_parameter_updates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.privacy_attacks.PassivePropertyInference.add_parameter_updates" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameter_updates</strong> – Tensor with dimension n * d_feature</p></li>
<li><p><strong>prop</strong> – Tensor with dimension  n * 1</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-federatedscope.attack.worker_as_attacker">
<span id="federatedscope-attack-worker-as-attacker"></span><h2>federatedscope.attack.worker_as_attacker<a class="headerlink" href="#module-federatedscope.attack.worker_as_attacker" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.BackdoorServer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.worker_as_attacker.</span></span><span class="sig-name descname"><span class="pre">BackdoorServer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ID</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_round_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unseen_clients_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#BackdoorServer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.BackdoorServer" title="Permalink to this definition">¶</a></dt>
<dd><p>For backdoor attacks, we will choose different sampling stratergies.
fix-frequency, all-round ,or random sampling.</p>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.BackdoorServer.broadcast_model_para">
<span class="sig-name descname"><span class="pre">broadcast_model_para</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">msg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'model_para'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_client_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_unseen_clients</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#BackdoorServer.broadcast_model_para"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.BackdoorServer.broadcast_model_para" title="Permalink to this definition">¶</a></dt>
<dd><p>To broadcast the message to all clients or sampled clients</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>msg_type</strong> – ‘model_para’ or other user defined msg_type</p></li>
<li><p><strong>sample_client_num</strong> – the number of sampled clients in the broadcast
behavior. And sample_client_num = -1 denotes to broadcast to
all the clients.</p></li>
<li><p><strong>filter_unseen_clients</strong> – whether filter out the unseen clients that
do not contribute to FL process by training on their local
data and uploading their local model update. The splitting is
useful to check participation generalization gap in [ICLR’22,
What Do We Mean by Generalization in Federated Learning?]
You may want to set it to be False when in evaluation stage</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.PassivePIAServer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.worker_as_attacker.</span></span><span class="sig-name descname"><span class="pre">PassivePIAServer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ID</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_round_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#PassivePIAServer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.PassivePIAServer" title="Permalink to this definition">¶</a></dt>
<dd><p>The implementation of the batch property classifier, the algorithm 3 in
paper: Exploiting Unintended Feature Leakage in Collaborative Learning</p>
<p>References:</p>
<p>Melis, Luca, Congzheng Song, Emiliano De Cristofaro and Vitaly
Shmatikov. “Exploiting Unintended Feature Leakage in Collaborative
Learning.” 2019 IEEE Symposium on Security and Privacy (SP) (2019): 691-706</p>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.PassivePIAServer.callback_funcs_model_para">
<span class="sig-name descname"><span class="pre">callback_funcs_model_para</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">federatedscope.core.message.Message</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#PassivePIAServer.callback_funcs_model_para"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.PassivePIAServer.callback_funcs_model_para" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>The handling function for receiving model parameters, which triggers</dt><dd><p>check_and_move_on (perform aggregation when enough feedback has
been received).</p>
</dd>
</dl>
<p>This handling function is widely used in various FL courses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>message</strong> – The received message, which includes sender, receiver,
state, and content. More detail can be found in
federatedscope.core.message</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.PassiveServer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">federatedscope.attack.worker_as_attacker.</span></span><span class="sig-name descname"><span class="pre">PassiveServer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ID</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_round_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_to_reconstruct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client_to_reconstruct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#PassiveServer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.PassiveServer" title="Permalink to this definition">¶</a></dt>
<dd><p>In passive attack, the server store the model and the message collected
from the client,and perform the optimization based reconstruction,
such as DLG, InvertGradient.</p>
<dl class="py method">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.PassiveServer.callback_funcs_model_para">
<span class="sig-name descname"><span class="pre">callback_funcs_model_para</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">federatedscope.core.message.Message</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/server_attacker.html#PassiveServer.callback_funcs_model_para"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.PassiveServer.callback_funcs_model_para" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>The handling function for receiving model parameters, which triggers</dt><dd><p>check_and_move_on (perform aggregation when enough feedback has
been received).</p>
</dd>
</dl>
<p>This handling function is widely used in various FL courses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>message</strong> – The received message, which includes sender, receiver,
state, and content. More detail can be found in
federatedscope.core.message</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.worker_as_attacker.plot_target_loss">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.worker_as_attacker.</span></span><span class="sig-name descname"><span class="pre">plot_target_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/worker_as_attacker/active_client.html#plot_target_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.worker_as_attacker.plot_target_loss" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss_list</strong> – the list of loss regrading the target data</p></li>
<li><p><strong>outdir</strong> – the directory to store the loss</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-federatedscope.attack.auxiliary">
<span id="federatedscope-attack-auxiliary"></span><h2>federatedscope.attack.auxiliary<a class="headerlink" href="#module-federatedscope.attack.auxiliary" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.create_ardis_poisoned_dataset">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">create_ardis_poisoned_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/create_edgeset.html#create_ardis_poisoned_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.create_ardis_poisoned_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>creating the poisoned FEMNIST dataset with edge-case triggers
we are going to label 7s from the ARDIS dataset as 1 (dirty label)
load the data from csv’s
We randomly select samples from the ardis dataset
consisting of 10 class (digits number).
fraction: the fraction for sampled data.
images_seven_DA: the multiple transformation version of dataset</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.get_data_info">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">get_data_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/utils.html#get_data_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.get_data_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the dataset information, including the feature dimension, number of
total classes, whether the label is represented in one-hot version</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataset_name</strong> – dataset name; str</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>data_feature_dim, num_class, is_one_hot_label</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.get_generator">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">get_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/utils.html#get_generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.get_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the dataset’s corresponding generator.
:param dataset_name: The dataset name; Type: str</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The generator; Type: object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.get_passive_PIA_auxiliary_dataset">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">get_passive_PIA_auxiliary_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/utils.html#get_passive_PIA_auxiliary_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.get_passive_PIA_auxiliary_dataset" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataset_name</strong> (<em>str</em>) – dataset name</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
<p>the auxiliary dataset for property inference attack. Type: dict</p>
<dl>
<dt>{</dt><dd><p>‘x’: array,
‘y’: array,
‘prop’: array</p>
<blockquote>
<div><p>}</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.get_reconstructor">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">get_reconstructor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atk_method</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/utils.html#get_reconstructor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.get_reconstructor" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>atk_method</strong> – the attack method name, and currently supporting “DLG:</p></li>
<li><p><strong>gradient&quot;</strong> (<em>deep leakage from</em>) – Inverting gradient” ; Type: str</p></li>
<li><p><strong>&quot;IG</strong> (<em>and</em>) – Inverting gradient” ; Type: str</p></li>
<li><p><strong>**kwargs</strong> – other arguments</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.iDLG_trick">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">iDLG_trick</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_one_hot_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/utils.html#iDLG_trick"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.iDLG_trick" title="Permalink to this definition">¶</a></dt>
<dd><p>Using iDLG trick to recover the label. Paper: “iDLG: Improved Deep
Leakage from Gradients”, link: <a class="reference external" href="https://arxiv.org/abs/2001.02610">https://arxiv.org/abs/2001.02610</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_gradient</strong> – the gradient of the FL model; type: list</p></li>
<li><p><strong>num_class</strong> – the total number of class in the data</p></li>
<li><p><strong>is_one_hot_label</strong> – whether the dataset’s label is in the form of one</p></li>
<li><p><strong>Type</strong> (<em>hot.</em>) – bool</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The recovered label by iDLG trick.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.auxiliary.selectTrigger">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.auxiliary.</span></span><span class="sig-name descname"><span class="pre">selectTrigger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trig_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trig_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">triggerType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/auxiliary/backdoor_utils.html#selectTrigger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.auxiliary.selectTrigger" title="Permalink to this definition">¶</a></dt>
<dd><p>return the img: np.array [0:255], (height, width, channel)</p>
</dd></dl>

</section>
<section id="module-federatedscope.attack.trainer">
<span id="federatedscope-attack-trainer"></span><h2>federatedscope.attack.trainer<a class="headerlink" href="#module-federatedscope.attack.trainer" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.hood_on_fit_start_generator">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">hood_on_fit_start_generator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/trainer/GAN_trainer.html#hood_on_fit_start_generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.hood_on_fit_start_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>count the FL training round before fitting
:param ctx ():</p>
<p>Returns:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.hook_on_batch_forward_injected_data">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">hook_on_batch_forward_injected_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/trainer/GAN_trainer.html#hook_on_batch_forward_injected_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.hook_on_batch_forward_injected_data" title="Permalink to this definition">¶</a></dt>
<dd><p>inject the generated data into training batch loss
:param ctx ():</p>
<p>Returns:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.hook_on_batch_injected_data_generation">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">hook_on_batch_injected_data_generation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/federatedscope/attack/trainer/GAN_trainer.html#hook_on_batch_injected_data_generation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.hook_on_batch_injected_data_generation" title="Permalink to this definition">¶</a></dt>
<dd><p>generate the injected data</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.wrap_GANTrainer">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">wrap_GANTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/federatedscope/attack/trainer/GAN_trainer.html#wrap_GANTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.wrap_GANTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Warp the trainer for gan_based class representative attack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>base_trainer</strong> – Type: core.trainers.GeneralTorchTrainer</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The wrapped trainer; Type: core.trainers.GeneralTorchTrainer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.wrap_GradientAscentTrainer">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">wrap_GradientAscentTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/federatedscope/attack/trainer/MIA_invert_gradient_trainer.html#wrap_GradientAscentTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.wrap_GradientAscentTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>wrap the gradient_invert trainer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>base_trainer</strong> – Type: core.trainers.GeneralTorchTrainer</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The wrapped trainer; Type: core.trainers.GeneralTorchTrainer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="federatedscope.attack.trainer.wrap_benignTrainer">
<span class="sig-prename descclassname"><span class="pre">federatedscope.attack.trainer.</span></span><span class="sig-name descname"><span class="pre">wrap_benignTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="core.html#federatedscope.core.trainers.GeneralTorchTrainer" title="federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer"><span class="pre">federatedscope.core.trainers.torch_trainer.GeneralTorchTrainer</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/federatedscope/attack/trainer/benign_trainer.html#wrap_benignTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#federatedscope.attack.trainer.wrap_benignTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Warp the benign trainer for backdoor attack:
We just add the normalization operation.
:param base_trainer: Type: core.trainers.GeneralTorchTrainer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The wrapped trainer; Type: core.trainers.GeneralTorchTrainer</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="autotune.html" class="btn btn-neutral float-left" title="Auto-tuning Module References" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mf.html" class="btn btn-neutral float-right" title="Federated Matrix Factorization Module References" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, The DAIL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>