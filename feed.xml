<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://federatedscopeteam.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://federatedscopeteam.github.io/" rel="alternate" type="text/html" /><updated>2023-09-06T05:40:29-04:00</updated><id>https://federatedscopeteam.github.io/feed.xml</id><title type="html">FederatedScope</title><subtitle>Easy Federated Learning, Safe Knowledge Sharing.</subtitle><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><entry><title type="html">FederatedScope: A Flexible Federated Learning Platform for Heterogeneity</title><link href="https://federatedscopeteam.github.io/federatedscope-core/" rel="alternate" type="text/html" title="FederatedScope: A Flexible Federated Learning Platform for Heterogeneity" /><published>2022-04-01T00:00:00-04:00</published><updated>2022-04-01T00:00:00-04:00</updated><id>https://federatedscopeteam.github.io/federatedscope-core</id><content type="html" xml:base="https://federatedscopeteam.github.io/federatedscope-core/">&lt;p&gt;Although remarkable progress has been made by the existing federated learning (FL) platforms to provide fundamental functionalities for development, these platforms cannot well tackle the challenges brought by the heterogeneity of FL scenarios from both academia and industry. 
To fill this gap, in this paper, we propose a flexible federated learning platform, named FederatedScope, for handling various types of heterogeneity in FL.
Considering both flexibility and extensibility, FederatedScope adopts an event-driven architecture to frame an FL course into event-handler pairs: the behaviors of participants are described in handlers, and triggered by events of message passing or meeting certain conditions in training.
For a new FL application, developers only need to specify the adopted FL algorithm by defining new types of events and the corresponding handling functions based on participants’ behaviors, which would be automatically executed in an asynchronous way for balancing effectiveness and efficiency in FederatedScope.
Meanwhile, towards an easy-to-use platform, FederatedScope provides rich built-in algorithms, including personalization, federated aggregation, privacy protection, and privacy attack, for users to conveniently customize participant-specific training, fusing, aggregating, and protecting.
Besides, a federated hyperparameter optimization module is integrated into FederatedScope for users to automatically tune their FL systems for resolving the unstable issues brought by heterogeneity.
We conduct a series of experiments on the provided easy-to-use and comprehensive FL benchmarks to validate the correctness and efficiency of FederatedScope. 
We have released FederatedScope for users on &lt;a href=&quot;https://github.com/alibaba/FederatedScope&quot;&gt;https://github.com/alibaba/FederatedScope&lt;/a&gt; to promote research and industrial deployment of federated learning in a variety of real-world applications.&lt;/p&gt;

&lt;p&gt;Yuexiang Xie, Zhen Wang, Daoyuan Chen, Dawei Gao, Liuyi Yao, Weirui Kuang, Yaliang Li, Bolin Ding, Jingren Zhou:
FederatedScope: A Flexible Federated Learning Platform for Heterogeneity
&lt;a href=&quot;https://arxiv.org/pdf/2204.05011.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="federated learning" /><category term="system" /><summary type="html">FederatedScope is a flexible and comprehensive federated learning platform proposed for tackling the heterogeneity in real-world federated learning applications. FederatedScope exploits an event-driven architecture to frame an FL course into multiple event-handler pairs for flexibly describing asynchronous federated learning with heterogeneous information exchanging, and provides rich built-in algorithms and the federated hyperparameter optimizer for conveniently resolving the unstable issues brought by heterogeneity.</summary></entry><entry><title type="html">FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning</title><link href="https://federatedscopeteam.github.io/federated-graph-learning/" rel="alternate" type="text/html" title="FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning" /><published>2022-02-10T00:00:00-05:00</published><updated>2022-02-10T00:00:00-05:00</updated><id>https://federatedscopeteam.github.io/federated-graph-learning</id><content type="html" xml:base="https://federatedscopeteam.github.io/federated-graph-learning/">&lt;p&gt;The incredible development of federated learning (FL) has benefited various tasks in the domains of computer vision and natural language processing, and the existing frameworks such as TFF and FATE has made the deployment easy in real-world applications.
However, federated graph learning (FGL), even though graph data are prevalent, has not been well supported due to its unique characteristics and requirements. The lack of FGL-related framework increases the efforts for accomplishing reproducible research and deploying in real-world applications.
Motivated by such strong demand, in this paper, we first discuss the challenges in creating an easy-to-use FGL package and accordingly present our implemented package FederatedScope-GNN, which provides (1) a unified view for modularizing and expressing FGL algorithms; (2) comprehensive DataZoo and ModelZoo for out-of-the-box FGL capability; (3) an efficient model auto-tuning component; and (4) off-the-shelf privacy attack and defense abilities. 
We validate the effectiveness of FederatedScope-GNN by conducting extensive experiments, which simultaneously gains many valuable insights about FGL for the community. Moreover, we employ FederatedScope-GNN to serve the FGL application in real-world E-commerce scenarios, where the attained improvements indicate great potential business benefits. We publicly release FederatedScope-GNN, as submodules of FederatedScope, at &lt;a href=&quot;https://github.com/alibaba/FederatedScope&quot;&gt;https://github.com/alibaba/FederatedScope&lt;/a&gt; to promote FGL’s research and enable broad applications that would otherwise be infeasible due to the lack of a dedicated package.&lt;/p&gt;

&lt;p&gt;Zhen Wang, Weirui Kuang, Yuexiang Xie, Liuyi Yao, Yaliang Li, Bolin Ding, Jingren Zhou:
FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning
&lt;a href=&quot;https://arxiv.org/pdf/2204.05562.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="federated learning" /><category term="graph" /><summary type="html">FederatedScope-GNN is an easy-to-use python package for federated graph learning. We built it upon FederatedScope so that the requirements for expressing federated graph learning algorithms can be met effortlessly. Benefiting from the comprehensive off-the-shelf datasets, splitters, graph neural network models, etc., we have set up many useful benchmarks for federated graph learning.</summary></entry><entry><title type="html">Federated Matrix Factorization with Privacy Guarantee</title><link href="https://federatedscopeteam.github.io/federated-matrix-factorization/" rel="alternate" type="text/html" title="Federated Matrix Factorization with Privacy Guarantee" /><published>2022-01-01T00:00:00-05:00</published><updated>2022-01-01T00:00:00-05:00</updated><id>https://federatedscopeteam.github.io/federated-matrix-factorization</id><content type="html" xml:base="https://federatedscopeteam.github.io/federated-matrix-factorization/">&lt;p&gt;Matrix factorization (MF) approximates unobserved ratings in a rating matrix, whose rows correspond to users and columns correspond to items to be rated, and has been serving as a fundamental building block in recommendation systems. This paper comprehensively studies the problem of matrix factorization in different federated learning (FL) settings, where a set of parties want to cooperate in training but refuse to share data directly. We first propose a generic algorithmic framework for various settings of federated matrix factorization (FMF) and provide a theoretical convergence guarantee. We then systematically characterize privacy-leakage risks in data collection, training, and publishing stages for three different settings and introduce privacy notions to provide end-to-end privacy protections. The first one is vertical federated learning (VFL), where multiple parties have the ratings from the same set of users but on disjoint sets of items. The second one is horizontal federated learning (HFL), where parties have ratings from different sets of users but on the same set of items. The third setting is local federated learning (LFL), where the ratings of the users are only stored on their local devices. We introduce adapted versions of FMF with the privacy notions guaranteed in the three settings. In particular, a new private learning technique called embedding clipping is introduced and used in all the three settings to ensure differential privacy. For the LFL setting, we combine differential privacy with secure aggregation to protect the communication between user devices and the server with a strength similar to the local differential privacy model, but much better accuracy. We perform experiments to demonstrate the effectiveness of our approaches.&lt;/p&gt;

&lt;p&gt;Zitao Li, Bolin Ding, Ce Zhang, Ninghui Li, Jingren Zhou:
Federated Matrix Factorization with Privacy Guarantee. Proc. VLDB Endow. 15(4): 900-913 (2021)
&lt;a href=&quot;https://www.bolin-ding.com/papers/vldb22fedmf.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="federated learning" /><category term="recommender system" /><summary type="html">Matrix factorization algorithms for recommender systems under both horizontal and vertical federated settings. Published in VLDB 2022.</summary></entry><entry><title type="html">Improving Utility and Security of the Shuffler-based Differential Privacy</title><link href="https://federatedscopeteam.github.io/shufflerdp/" rel="alternate" type="text/html" title="Improving Utility and Security of the Shuffler-based Differential Privacy" /><published>2020-12-01T00:00:00-05:00</published><updated>2020-12-01T00:00:00-05:00</updated><id>https://federatedscopeteam.github.io/shufflerdp</id><content type="html" xml:base="https://federatedscopeteam.github.io/shufflerdp/">&lt;p&gt;When collecting information, local differential privacy (LDP) alleviates privacy concerns of users because their private information is randomized before being sent it to the central aggregator. LDP imposes large amount of noise as each user executes the randomization independently. To address this issue, recent work introduced an intermediate server with the assumption that this intermediate server does not collude with the aggregator. Under this assumption, less noise can be added to achieve the same privacy guarantee as LDP, thus improving utility for the data collection task.&lt;/p&gt;

&lt;p&gt;This paper investigates this multiple-party setting of LDP. We analyze the system model and identify potential adversaries. We then make two improvements: a new algorithm that achieves a better privacy-utility tradeoff; and a novel protocol that provides better protection against various attacks. Finally, we perform experiments to compare different methods and demonstrate the benefits of using our proposed method.&lt;/p&gt;

&lt;p&gt;Tianhao Wang, Bolin Ding, Min Xu, Zhicong Huang, Cheng Hong, Jingren Zhou, Ninghui Li, Somesh Jha:
Improving Utility and Security of the Shuffler-based Differential Privacy. Proc. VLDB Endow. 13(13): 3545-3558 (2020)
&lt;a href=&quot;https://www.bolin-ding.com/papers/vldb20shufflerdp.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="frequency queries" /><category term="local differential privacy" /><category term="privacy amplification" /><category term="multiple-party computation" /><summary type="html">For frequency queries, introducing a new algorithm that achieves a better privacy-utility tradeoff via shuffling and a novel protocol that provides better protection against various attacks. Published in VLDB 2021.</summary></entry><entry><title type="html">Collecting and Analyzing Data Jointly from Multiple Services under Local Differential Privacy</title><link href="https://federatedscopeteam.github.io/jointldp/" rel="alternate" type="text/html" title="Collecting and Analyzing Data Jointly from Multiple Services under Local Differential Privacy" /><published>2020-10-01T00:00:00-04:00</published><updated>2020-10-01T00:00:00-04:00</updated><id>https://federatedscopeteam.github.io/jointldp</id><content type="html" xml:base="https://federatedscopeteam.github.io/jointldp/">&lt;p&gt;Users’ sensitive data can be collected and analyzed under local differential privacy (LDP) without the need to trust the data collector. Most previous work on LDP can be applied when each user’s data is generated and collected from a single service or data source. In a more general and practical setting, sensitive data of each user needs to be collected under LDP from multiple services independently and can be joined on, e.g., user id. In this paper, we address two challenges in this setting: first, how to prevent the privacy guarantee from being weakened during the joint data collection; second, how to analyze perturbed data jointly from different services. We introduce the notation of user-level LDP to formalize and protect the privacy of a user when her joined data tuples are released. We propose mechanisms and estimation methods to process multidimensional analytical queries, each with sensitive attributes (in its aggregation and predicates) collected and perturbed independently in multiple services. We also introduce an online utility optimization technique for multi-dimensional range predicates, based on consistency in domain hierarchy. We conduct extensive evaluations to verify our theoretical results using synthetic and real datasets.&lt;/p&gt;

&lt;p&gt;Min Xu, Bolin Ding, Tianhao Wang, Jingren Zhou:
Collecting and Analyzing Data Jointly from Multiple Services under Local Differential Privacy. Proc. VLDB Endow. 13(11): 2760-2772 (2020)
&lt;a href=&quot;https://www.bolin-ding.com/papers/vldb20jointldp.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="federated data analytics" /><category term="local differential privacy" /><category term="frequency-based attack" /><summary type="html">Techniques for collecting data from each service independently and analyzing the data from multiple services jointly, with privacy guarantees. Published in VLDB 2020.</summary></entry><entry><title type="html">DPSAaS: Multi-Dimensional Data Sharing and Analytics as Services under Local Differential Privacy</title><link href="https://federatedscopeteam.github.io/dpsaas/" rel="alternate" type="text/html" title="DPSAaS: Multi-Dimensional Data Sharing and Analytics as Services under Local Differential Privacy" /><published>2019-12-01T00:00:00-05:00</published><updated>2019-12-01T00:00:00-05:00</updated><id>https://federatedscopeteam.github.io/dpsaas</id><content type="html" xml:base="https://federatedscopeteam.github.io/dpsaas/">&lt;p&gt;Differential privacy has emerged as the de facto standard for privacy definitions, and been used by, e.g., Apple, Google, Uber, and Microsoft, to collect sensitive information about users and to build privacy-preserving analytics engines. However, most of such advanced privacy-protection techniques are not accessible to mid-size companies and app developers in the cloud. We demonstrate a lightweight middleware DPSAaS, which provides &lt;u&gt;d&lt;/u&gt;ifferentially &lt;u&gt;p&lt;/u&gt;rivate data-&lt;u&gt;s&lt;/u&gt;haring-and-&lt;u&gt;a&lt;/u&gt;nalytics functionality &lt;u&gt;a&lt;/u&gt;s cloud &lt;u&gt;s&lt;/u&gt;ervices.&lt;/p&gt;

&lt;p&gt;We focus on multi-dimensional analytical (MDA) queries under local differential privacy (LDP) in this demo. MDA queries against a fact table have predicates on (categorical or ordinal) dimensions and aggregate one or more measures. In the absence of a trusted agent, sensitive dimensions and measures are encoded in a privacy-preserving way locally using our LDP data sharing service, before being sent to the data collector. The data collector estimates the answers to MDA queries from the encoded data, using our data analytics service. We will highlight the design decisions of DPSAaS and twists made to LDA algorithms to fit the design, in order to smoothly connect DPSAaS to the data processing platform and analytics engines, and to facilitate efficient large-scale processing.&lt;/p&gt;

&lt;p&gt;Min Xu, Tianhao Wang, Bolin Ding, Jingren Zhou, Cheng Hong, Zhicong Huang:
DPSAaS: Multi-Dimensional Data Sharing and Analytics as Services under Local Differential Privacy. Proc. VLDB Endow. 12(12): 1862-1865 (2019)
&lt;a href=&quot;https://www.bolin-ding.com/papers/vldb19DPSAaS.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="multi-dimensional analytical (MDA) queries" /><category term="local differential privacy" /><category term="federated data analytics" /><category term="system" /><summary type="html">We design and demonstrate a lightweight middleware called DPSAaS, which provides differentially private data-sharing-and-analytics functionality as cloud services. Published in VLDB 2019.</summary></entry><entry><title type="html">Answering Multi-Dimensional Analytical Queries under Local Differential Privacy</title><link href="https://federatedscopeteam.github.io/mdaquery/" rel="alternate" type="text/html" title="Answering Multi-Dimensional Analytical Queries under Local Differential Privacy" /><published>2019-10-01T00:00:00-04:00</published><updated>2019-10-01T00:00:00-04:00</updated><id>https://federatedscopeteam.github.io/mdaquery</id><content type="html" xml:base="https://federatedscopeteam.github.io/mdaquery/">&lt;p&gt;Multi-dimensional analytical (MDA) queries are often issued against a fact table with predicates on (categorical or ordinal) dimensions and aggregations on one or more measures. In this paper, we study the problem of answering MDA queries under local differential privacy (LDP). In the absence of a trusted agent, sensitive dimensions are encoded in a privacy-preserving (LDP) way locally before being sent to the data collector. The data collector estimates the answers to MDA queries, based on the encoded dimensions. We propose several LDP encoders and estimation algorithms, to handle a large class of MDA queries with different types of predicates and aggregation functions. Our techniques are able to answer these queries with tight error bounds and scale well in high-dimensional settings (i.e., error is polylogarithmic in dimension sizes). We conduct experiments on real and synthetic data to verify our theoretical results, and compare our solution with marginal-estimation based solutions.&lt;/p&gt;

&lt;p&gt;Tianhao Wang, Bolin Ding, Jingren Zhou, Cheng Hong, Zhicong Huang, Ninghui Li, Somesh Jha:
Answering Multi-Dimensional Analytical Queries under Local Differential Privacy. SIGMOD Conference 2019: 159-176
&lt;a href=&quot;https://www.bolin-ding.com/papers/sigmod19ldpmda.pdf&quot;&gt;download&lt;/a&gt;&lt;/p&gt;</content><author><name>Data Analytics and Intelligence Lab (DAIL) of DAMO Academy</name></author><category term="multi-dimensional analytical (MDA) queries" /><category term="local differential privacy" /><category term="federated data analytics" /><summary type="html">Algorithms for answering multi-dimensional analytical (MDA) queries approximately under local differential privacy. Published in SIGMOD 2019.</summary></entry></feed>